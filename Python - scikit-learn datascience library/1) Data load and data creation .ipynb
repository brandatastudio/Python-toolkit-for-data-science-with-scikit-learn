{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show functions used during data science cases, when loading or creating data for our projects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following functions and processes are used when, for doing data science, we use real data that we can either download or \n",
    "have stored in our local system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example if the data is in local server in csv format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.050</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.99160</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>27.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.15</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.119</td>\n",
       "      <td>56.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99578</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.080</td>\n",
       "      <td>11.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99538</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.60</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.043</td>\n",
       "      <td>24.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           5.20              0.34         0.00             1.8      0.050   \n",
       "1           6.20              0.55         0.45            12.0      0.049   \n",
       "2           7.15              0.17         0.24             9.6      0.119   \n",
       "3           6.70              0.64         0.23             2.1      0.080   \n",
       "4           7.60              0.23         0.34             1.6      0.043   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 27.0                  63.0  0.99160  3.68       0.79   \n",
       "1                 27.0                 186.0  0.99740  3.17       0.50   \n",
       "2                 56.0                 178.0  0.99578  3.15       0.44   \n",
       "3                 11.0                 119.0  0.99538  3.36       0.70   \n",
       "4                 24.0                 129.0  0.99305  3.12       0.70   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0     14.0        6    red  \n",
       "1      9.3        6  white  \n",
       "2     10.2        6  white  \n",
       "3     10.9        5    red  \n",
       "4     10.4        5  white  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datapath = 'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\python\\\\winequality.csv' \n",
    "# place here the path of the file you are loading, if you have it on your local computer\n",
    "\n",
    "winedata = pd.read_csv(datapath,sep = ';') # make sure to check the separator for your case\n",
    "\n",
    "winedata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example if the data is in a tarz file, somewhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading the tarz file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "os.getcwd() # we first check where we are, to there indicate where the file will be placed once downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_URL = \"http://www.dcc.fc.up.pt/~ltorgo/Regression/\" # here we place the url where the file we want to extract is \n",
    "\n",
    "HOUSING_FILENAME = \"cal_housing.tgz\" # we put the name of the file we want to extract. \n",
    "\n",
    "HOUSING_PATH = 'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library' # where we want to place the file, inside of our\n",
    "# computer or server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH, housing_file=HOUSING_FILENAME):\n",
    "    \"\"\"\n",
    "    This function allows us to obtain a certain .tar file, located in a certain url, save it in a local\n",
    "    directory of our choice and extract it there. Arguments:\n",
    "    \n",
    "        - housing_url: Where the file we want, is located.\n",
    "        - housing_path: Local path where we want to place said file.\n",
    "        - housing_file: Name of the file.\n",
    "\"\"\"\n",
    "\n",
    "    # this first part of the function make sure that the housing_path we give does exists, if it does not, it creates a directory\n",
    "    # to place the file in. \n",
    "    if not os.path.isdir(housing_path):\n",
    "        print(housing_path,\"does not exist, it will be created...\")\n",
    "        os.makedirs(housing_path)\n",
    "        print(housing_path,\"created!\")\n",
    "    \n",
    "    # this creates a tgz_path joining the housing path and the file. \n",
    "    tgz_path = os.path.join(housing_path, housing_file)\n",
    "    \n",
    "    # Here we create an user agent and make a request to the url in question, creating a request object\n",
    "    header = {'User-Agent': 'Mozilla/5.0'}\n",
    "    print(\"requesting housing dataset at\",housing_url)\n",
    "    response = requests.get(housing_url + housing_file, headers=header)\n",
    "    \n",
    "   # We check if the request object response has been correctly processed or not, if it has, we start downloading the content\n",
    "    if(response.status_code == 200):\n",
    "        with open(tgz_path, 'wb') as handle:\n",
    "            for block in response.iter_content(1024):\n",
    "                handle.write(block)\n",
    "            print(\"download complete!\")\n",
    "    else : \n",
    "        print(\" request failed \")\n",
    "    \n",
    "    # Finally, we extract the file. \n",
    "    print(\"Untarring files...\")\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    print(\"Extraction complete!\")\n",
    "    housing_tgz.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting housing dataset at http://www.dcc.fc.up.pt/~ltorgo/Regression/\n",
      "download complete!\n",
      "Untarring files...\n",
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "fetch_housing_data() # with this, now we have the data downloaded in our local, so we can just create the dataframe like we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data loaded in our local computer, we now create a local data file that joins the different files that come in tarz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude: continuous.\n",
      "latitude: continuous.\n",
      "housingMedianAge: continuous. \n",
      "totalRooms: continuous. \n",
      "totalBedrooms: continuous. \n",
      "population: continuous. \n",
      "households: continuous. \n",
      "medianIncome: continuous. \n",
      "medianHouseValue: continuous. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First we check the files we have \n",
    "\n",
    "with open(HOUSING_UNTAR_PATH + \"/cal_housing.domain\") as header_file:\n",
    "    print(header_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000\n",
      "\n",
      "-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000\n",
      "\n",
      "-122.240000,37.850000,52.000000,1467.000000,190.000000,496.000000,177.000000,7.257400,352100.000000\n",
      "\n",
      "-122.250000,37.850000,52.000000,1274.000000,235.000000,558.000000,219.000000,5.643100,341300.000000\n",
      "\n",
      "-122.250000,37.850000,52.000000,1627.000000,280.000000,565.000000,259.000000,3.846200,342200.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_lines = 5\n",
    "with open(HOUSING_UNTAR_PATH + \"/cal_housing.data\") as data_file:\n",
    "    for line in np.arange(n_lines):\n",
    "        print(next(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library/housing.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we create a path for the directory, inside our local computer where our data is placed\n",
    "HOUSING_UNTAR_PATH = HOUSING_PATH + \"/CaliforniaHousing\"\n",
    "#  In this case, data is separated in \" domains\" and the \"actual data\" we will combine them in a csv, first we will create the \n",
    "# destination file\n",
    "HOUSING_TOTAL_FILENAME = \"housing.csv\"\n",
    "# We create a complete route where we will place that destination file inside our directory. \n",
    "HOUSING_TOTAL_PATH = HOUSING_PATH + \"/\" + HOUSING_TOTAL_FILENAME\n",
    "\n",
    "HOUSING_TOTAL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_housing_data(housing_untar_path=HOUSING_UNTAR_PATH, housing_total_path=HOUSING_TOTAL_PATH):\n",
    "    import glob \n",
    "    \n",
    "    \"\"\"\n",
    "    This function will analyze the directory where the tarz file was extracted, it will process the .domain file leaving only the feature names, and \\\n",
    "    it will place it in the csv destination file, with the content of the file containing the data\n",
    "    \n",
    "\n",
    "    Argumentos:\n",
    "        - housing_untar_path: The directory where we have the files, after downloading tarz.\n",
    "        - housing_total_path: The route of the destination file, where we will place the data .    \n",
    "    \"\"\"\n",
    "    # glob.glob permitirá listar los ficheros contenidos en el directorio\n",
    "    # sorted permitirá ordenar los ficheros obtenidos mediante glob.glob según el criterio\n",
    "    # indicado, en este caso el tamaño (de menor a mayor tamaño).\n",
    "    concat_files = sorted(glob.glob(housing_untar_path + \"/*\"), key=os.path.getsize)\n",
    "    print(\"Merging files...\",concat_files)\n",
    "    with open(housing_total_path,\"w\") as outfile:\n",
    "        for part_file in concat_files:\n",
    "            with open(part_file, \"r\") as infile:\n",
    "                # El fichero con los nombres de los campos será aplanado de manera que al final quede una\n",
    "                # única línea: campo1, campo2, campo3, campo4...\n",
    "                if(\".domain\" in part_file):\n",
    "                    # Primero se leen todas sus líneas (el nombre de cada feature y su tipo)\n",
    "                    raw_header = infile.readlines()\n",
    "                    # Luego suprime el tipo (\": continous\") metiendo el resultado en una lista\n",
    "                    header = [ field.replace(\": continuous.\",\"\").strip() for field in raw_header]\n",
    "                    # Une cada elemento de la lista por \",\" y vuelca el resultado en el fichero de salida\n",
    "                    outfile.write(\",\".join(header)+\"\\n\")\n",
    "                else:\n",
    "                    outfile.write(infile.read())   \n",
    "    print(\"Files merged into\",outfile.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging files... ['C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library/CaliforniaHousing\\\\cal_housing.domain', 'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library/CaliforniaHousing\\\\cal_housing.data']\n",
      "Files merged into C:\\Users\\stefano\\Dropbox\\Aprendizaje util\\Programacion learning\\modulo machine learning\\Python - scikit-learn datascience library/housing.csv\n"
     ]
    }
   ],
   "source": [
    "merge_housing_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0    -122.23     37.88              41.0       880.0          129.0   \n",
       "1    -122.22     37.86              21.0      7099.0         1106.0   \n",
       "2    -122.24     37.85              52.0      1467.0          190.0   \n",
       "3    -122.25     37.85              52.0      1274.0          235.0   \n",
       "4    -122.25     37.85              52.0      1627.0          280.0   \n",
       "\n",
       "   population  households  medianIncome  medianHouseValue  \n",
       "0       322.0       126.0        8.3252          452600.0  \n",
       "1      2401.0      1138.0        8.3014          358500.0  \n",
       "2       496.0       177.0        7.2574          352100.0  \n",
       "3       558.0       219.0        5.6431          341300.0  \n",
       "4       565.0       259.0        3.8462          342200.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = 'C:\\\\Users\\\\stefano\\\\Dropbox\\\\Aprendizaje util\\\\Programacion learning\\\\modulo machine learning\\\\Python - scikit-learn datascience library\\\\housing.csv'\n",
    "import pandas as  pd\n",
    "housingdata = pd.read_csv(datapath,sep = ',')\n",
    "\n",
    "housingdata.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create gaussian samples, using make_blobs from scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.96455381,   0.46894968],\n",
       "        [ -1.21779287, -11.15836353],\n",
       "        [  1.80183704,  -2.1877917 ],\n",
       "        [ -2.10087691,  -3.74757963],\n",
       "        [ -0.45292089,  -6.04316334],\n",
       "        [ -0.52577983, -11.34940749],\n",
       "        [ -0.12855687,  -1.28001427],\n",
       "        [ -1.20778828,  -4.87647215],\n",
       "        [ -2.9098058 ,  -3.62795484],\n",
       "        [ -2.86703029, -10.84498679]]), array([1, 0, 1, 2, 0, 0, 1, 2, 2, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# details here : https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html \n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "my_dataset = make_blobs(n_samples=10,     # Number of interactions or rows we create for the dataset \n",
    "                               n_features=2,     # Number of variables we are going to use\n",
    "                               centers=3,        # number of gaussian centers the data distribution will have\n",
    "                               cluster_std=1.5,  #typical deviation of the data \n",
    "                               random_state=2)   # If we want to specify a seed for the data \n",
    "\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964554</td>\n",
       "      <td>0.468950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.217793</td>\n",
       "      <td>-11.158364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.801837</td>\n",
       "      <td>-2.187792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.100877</td>\n",
       "      <td>-3.747580</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.452921</td>\n",
       "      <td>-6.043163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.525780</td>\n",
       "      <td>-11.349407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.128557</td>\n",
       "      <td>-1.280014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.207788</td>\n",
       "      <td>-4.876472</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.909806</td>\n",
       "      <td>-3.627955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.867030</td>\n",
       "      <td>-10.844987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y  label\n",
       "0  0.964554   0.468950      1\n",
       "1 -1.217793 -11.158364      0\n",
       "2  1.801837  -2.187792      1\n",
       "3 -2.100877  -3.747580      2\n",
       "4 -0.452921  -6.043163      0\n",
       "5 -0.525780 -11.349407      0\n",
       "6 -0.128557  -1.280014      1\n",
       "7 -1.207788  -4.876472      2\n",
       "8 -2.909806  -3.627955      2\n",
       "9 -2.867030 -10.844987      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The make_blobs function returns two objects, one with the data , for wich we will create a dataframe, and another one for \n",
    "# the labels of the data that specify their center we will add as a colum to the dataframe or we can just ignore it. \n",
    "\n",
    "dataset_blobs = pd.DataFrame(my_dataset[0])  \n",
    "\n",
    "dataset_blobs.columns = [\"x\", \"y\"]\n",
    "\n",
    "dataset_blobs[\"label\"] = my_dataset[1]  \n",
    "\n",
    "dataset_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using scikit learn generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data for a regression excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\stefano\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "datos_boston = load_boston()\n",
    "\n",
    "datos_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_boston = pd.DataFrame(datos_boston[\"data\"])\n",
    "# If we open the datos_boston, we see we have different objects,  , we will create the feature names as colums, we will add the data\n",
    "# as the rows of those colums, and add the target , creating a complete dataframe to work with. \n",
    "\n",
    "dataset_boston.columns = datos_boston[\"feature_names\"]\n",
    "dataset_boston[\"target\"] = datos_boston[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data for a classification excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "dataset = make_classification(n_samples=600, # Number of rows or interactions\n",
    "                              n_features=2, # Number of features\n",
    "                              n_redundant=0, # Number of redundant features\n",
    "                              n_classes=2, # Number of classes for the target variable\n",
    "                              random_state=749 # Seed generator\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574208</td>\n",
       "      <td>1.609926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.666932</td>\n",
       "      <td>-0.698694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.452082</td>\n",
       "      <td>-2.546917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.854633</td>\n",
       "      <td>-0.364912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277625</td>\n",
       "      <td>-0.411260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  label\n",
       "0  0.574208  1.609926      1\n",
       "1 -0.666932 -0.698694      0\n",
       "2  0.452082 -2.546917      1\n",
       "3 -0.854633 -0.364912      0\n",
       "4 -0.277625 -0.411260      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first create a dataframe for the features\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "dataset_clasificacion = pd.DataFrame(dataset[0])\n",
    "\n",
    "# then the labels\n",
    "dataset_clasificacion[\"label\"] = dataset[1]\n",
    "\n",
    "dataset_clasificacion[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
